{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting models on Grid\n",
    "\n",
    "Grid offers both: Machine Learning as a Service and Encrypted Machine Learning as a service. This is a series of notebooks showing how you can serve your models on Grid.\n",
    "\n",
    "## 1. Train a model\n",
    "\n",
    "First of all we need to train a model. Here we replicate the tutorial from [Nyla Pirani](https://towardsdatascience.com/@nyla.pirani) that shows [how to train a Pytorch model for skin cancer](https://towardsdatascience.com/skin-cancer-classification-with-machine-learning-c9d3445b2163).\n",
    "\n",
    "### Use case: Skin cancer prediction\n",
    "\n",
    "Here we'll implement a model for detecting types of skin cancer on images.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We'll use this [kaggle dataset](https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000/). You need to download this dataset before running this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "DATASET_PATH = \"./skin-cancer-mnist-ham10000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(DATASET_PATH, '*', '*.jpg'))}\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "tile_df = pd.read_csv(os.path.join(DATASET_PATH, 'HAM10000_metadata.csv'))\n",
    "tile_df['path'] = tile_df['image_id'].map(imageid_path_dict.get)\n",
    "tile_df['cell_type'] = tile_df['dx'].map(lesion_type_dict.get) \n",
    "tile_df['cell_type_idx'] = pd.Categorical(tile_df['cell_type']).codes\n",
    "tile_df[['cell_type_idx', 'cell_type']].sort_values('cell_type_idx').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_df['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1 sample from each class\n",
    "samples = tile_df.groupby('cell_type').apply(lambda x: x.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "columns = 3\n",
    "rows = 2\n",
    "for i in range(columns * rows):\n",
    "    image = mpimg.imread(samples[\"path\"].iloc[i])\n",
    "    fig.add_subplot(rows, columns, i + 1)\n",
    "    plt.imshow(image)\n",
    "    title = \"{} ({})\".format(samples[\"cell_type_idx\"].iloc[i], samples[\"cell_type\"].iloc[i])\n",
    "    plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(tile_df, test_size=0.1)\n",
    "# We can split the test set again in a validation set and a true test set:\n",
    "validation_df, test_df = train_test_split(test_df, test_size=0.5)\n",
    "train_df = train_df.reset_index()\n",
    "validation_df = validation_df.reset_index()\n",
    "test_df = test_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "# Define the parameters for the dataloader\n",
    "params = {'batch_size': 4,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transformation of the images.\n",
    "import torchvision.transforms as trf\n",
    "composed = trf.Compose([trf.RandomHorizontalFlip(), trf.RandomVerticalFlip(), trf.CenterCrop(256), trf.RandomCrop(224),  trf.ToTensor(),\n",
    "                        trf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Define the trainingsset using the table train_df and using our defined transitions (composed)\n",
    "training_set = Dataset(train_df, transform=composed)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "# Same for the validation set:\n",
    "validation_set = Dataset(validation_df, transform=composed)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "def make_model(num_classes: int):\n",
    "    \"\"\"Load a vgg16 and add a new head to it.\"\"\"\n",
    "    model = models.densenet121(pretrained=True)\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = torch.nn.Linear(num_ftrs, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "trainings_error = []\n",
    "validation_error = []\n",
    "for epoch in range(max_epochs):\n",
    "    print('epoch:', epoch)\n",
    "    count_train = 0\n",
    "    trainings_error_tmp = []\n",
    "    model.train()\n",
    "    for data_sample, y in training_generator:\n",
    "        data_gpu = data_sample.to(device)\n",
    "        y_gpu = y.to(device)\n",
    "        output = model(data_gpu)\n",
    "        err = criterion(output, y_gpu)\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "        trainings_error_tmp.append(err.item())\n",
    "        count_train += 1\n",
    "        if count_train >= 100:\n",
    "            count_train = 0\n",
    "            mean_trainings_error = np.mean(trainings_error_tmp)\n",
    "            trainings_error.append(mean_trainings_error)\n",
    "            print('trainings error:', mean_trainings_error)\n",
    "            break\n",
    "    with torch.set_grad_enabled(False):\n",
    "        validation_error_tmp = []\n",
    "        count_val = 0\n",
    "        model.eval()\n",
    "        for data_sample, y in validation_generator:\n",
    "            data_gpu = data_sample.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            output = model(data_gpu)\n",
    "            err = criterion(output, y_gpu)\n",
    "            validation_error_tmp.append(err.item())\n",
    "            count_val += 1\n",
    "            if count_val >= 10:\n",
    "                count_val = 0\n",
    "                mean_val_error = np.mean(validation_error_tmp)\n",
    "                validation_error.append(mean_val_error)\n",
    "                print('validation error:', mean_val_error)\n",
    "                break\n",
    "plt.plot(trainings_error, label = 'training error')\n",
    "plt.plot(validation_error, label = 'validation error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_set = Dataset(validation_df, transform=composed)\n",
    "test_generator = torch.utils.data.SequentialSampler(validation_set)\n",
    "result_array = []\n",
    "gt_array = []\n",
    "for i in test_generator:\n",
    "    data_sample, y = validation_set.__getitem__(i)\n",
    "    data_gpu = data_sample.unsqueeze(0).to(device)\n",
    "    output = model(data_gpu)\n",
    "    result = torch.argmax(output)\n",
    "    result_array.append(result.item())\n",
    "    gt_array.append(y.item())\n",
    "correct_results = np.array(result_array)==np.array(gt_array)\n",
    "sum_correct = np.sum(correct_results)\n",
    "accuracy = sum_correct/test_generator.__len__()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet-skin-cancer-detection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "syft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
