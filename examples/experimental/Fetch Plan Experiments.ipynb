{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import grid as gr\n",
    "\n",
    "# Hook\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "    \n",
    "# Connect to nodes\n",
    "alice = gr.WebsocketGridClient(hook, \"http://localhost:3001\", id=\"Alice\")\n",
    "alice.connect()\n",
    "bob = gr.WebsocketGridClient(hook, \"http://localhost:3000\", id=\"Bob\")\n",
    "charlie = gr.WebsocketGridClient(hook, \"http://localhost:3002\", id=\"James\")\n",
    "dan = gr.WebsocketGridClient(hook, \"http://localhost:3003\", id=\"Dan\")\n",
    "bob.connect()\n",
    "charlie.connect()\n",
    "dan.connect()\n",
    "\n",
    "gr.connect_all_nodes([bob, alice, charlie, dan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0209]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Model Owner\n",
    "# Support fetch plan + AST tensor\n",
    "class Net(sy.Plan):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__(id=\"convnet\")\n",
    "        self.conv1 = nn.Conv2d(3, 4, 5, 1)\n",
    "        self.fc1 = nn.Linear(3136, 40)\n",
    "        self.fc2 = nn.Linear(40, 1)\n",
    "\n",
    "        self.add_to_state([\"conv1\", \"fc1\", \"fc2\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 3136)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "plan = Net()\n",
    "    \n",
    "data_shape = (1, 3, 32, 32)\n",
    "data = th.zeros(data_shape)\n",
    "plan.build(data)\n",
    "print(plan(data))\n",
    "    \n",
    "sent_plan = plan.send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "def restart_kernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "    \n",
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import grid as gr\n",
    "\n",
    "# Hook\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "    \n",
    "# Connect to nodes\n",
    "alice = gr.WebsocketGridClient(hook, \"http://localhost:3001\", id=\"Alice\")\n",
    "alice.connect()\n",
    "bob = gr.WebsocketGridClient(hook, \"http://localhost:3000\", id=\"Bob\")\n",
    "charlie = gr.WebsocketGridClient(hook, \"http://localhost:3002\", id=\"James\")\n",
    "dan = gr.WebsocketGridClient(hook, \"http://localhost:3003\", id=\"Dan\")\n",
    "bob.connect()\n",
    "charlie.connect()\n",
    "dan.connect()\n",
    "\n",
    "gr.connect_all_nodes([bob, alice, charlie, dan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch plan\n",
    "fetched_plan = alice.fetch_plan(\"convnet\")\n",
    "data_shape = (1, 3, 32, 32)\n",
    "data = th.zeros(data_shape)\n",
    "x_ptr = data.fix_prec().share(bob, charlie, crypto_provider=dan)\n",
    "\n",
    "# TODO: this should be stored automatically\n",
    "me._objects[x_ptr.id] = x_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{26521377524: (Wrapper)>[PointerTensor | me:56353713837 -> Alice:64965785327],\n",
       " 56353713837: (Wrapper)>[PointerTensor | me:56353713837 -> Alice:64965785327],\n",
       " 12032377909: (Wrapper)>[PointerTensor | me:69960128432 -> Alice:92969008696],\n",
       " 69960128432: (Wrapper)>[PointerTensor | me:69960128432 -> Alice:92969008696],\n",
       " 96250629554: (Wrapper)>[PointerTensor | me:715510378 -> Alice:84862814872],\n",
       " 715510378: (Wrapper)>[PointerTensor | me:715510378 -> Alice:84862814872],\n",
       " 30122723808: (Wrapper)>[PointerTensor | me:35644423231 -> Alice:1698717535],\n",
       " 35644423231: (Wrapper)>[PointerTensor | me:35644423231 -> Alice:1698717535],\n",
       " 18164706485: (Wrapper)>[PointerTensor | me:51752319607 -> Alice:20180829760],\n",
       " 51752319607: (Wrapper)>[PointerTensor | me:51752319607 -> Alice:20180829760],\n",
       " 67972504464: (Wrapper)>[PointerTensor | me:16002842495 -> Alice:94412804842],\n",
       " 16002842495: (Wrapper)>[PointerTensor | me:16002842495 -> Alice:94412804842],\n",
       " 97739968624: tensor(4611686018427387904),\n",
       " 48332848142: (Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       " \t-> [PointerTensor | me:66004538797 -> Bob:39627766793]\n",
       " \t-> [PointerTensor | me:75545337890 -> James:9205752384]\n",
       " \t*crypto provider: Dan*}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this should be done internally\n",
    "new_state_ids = []\n",
    "for state_id in fetched_plan.state_ids:\n",
    "    # TODO: we should not have direct access to the weights\n",
    "    a_sh = me._objects[state_id].fix_prec().share(bob, charlie, crypto_provider=dan).get()\n",
    "    # TODO: this should be stored automatically\n",
    "    me._objects[a_sh.id] = a_sh\n",
    "    new_state_ids.append(a_sh.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56353713837, 69960128432, 715510378, 35644423231, 51752319607, 16002842495]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_plan.state_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_plan.replace_ids(fetched_plan.state_ids, new_state_ids)\n",
    "fetched_plan.state_ids = new_state_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0200]])\n",
      "CPU times: user 16.7 s, sys: 4.87 s, total: 21.6 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(fetched_plan(x_ptr).get().float_prec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net2\n"
     ]
    }
   ],
   "source": [
    "# Support fetching a plan\n",
    "plan_func = False\n",
    "\n",
    "if plan_func:\n",
    "    @sy.func2plan(args_shape=[(1,)], state={\"bias\": th.tensor([3.0])})\n",
    "    def plan_mult_3(x, state):\n",
    "        bias = state.read(\"bias\")\n",
    "        x = x * bias\n",
    "        return x\n",
    "else:\n",
    "    class Net(sy.Plan):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__(id=\"net2\")\n",
    "            self.fc1 = nn.Linear(1, 1)\n",
    "            self.add_to_state([\"fc1\"])\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.fc1(x)\n",
    "    \n",
    "    plan_mult_3 = Net()\n",
    "    plan_mult_3.build(th.tensor(1))\n",
    "\n",
    "sent_plan = plan_mult_3.send(alice)\n",
    "print(sent_plan.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "def restart_kernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "    \n",
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import grid as gr\n",
    "\n",
    "# Hook\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "    \n",
    "# Connect to nodes\n",
    "alice = gr.WebsocketGridClient(hook, \"http://localhost:3001\", id=\"Alice\")\n",
    "alice.connect()\n",
    "bob = gr.WebsocketGridClient(hook, \"http://localhost:3000\", id=\"Bob\")\n",
    "charlie = gr.WebsocketGridClient(hook, \"http://localhost:3002\", id=\"James\")\n",
    "dan = gr.WebsocketGridClient(hook, \"http://localhost:3003\", id=\"Dan\")\n",
    "bob.connect()\n",
    "charlie.connect()\n",
    "dan.connect()\n",
    "\n",
    "gr.connect_all_nodes([bob, alice, charlie, dan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch plan\n",
    "fetched_plan = alice.fetch_plan(\"net2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this should be done internally\n",
    "new_state_ids = []\n",
    "for state_id in fetched_plan.state_ids:\n",
    "    # TODO: we should not have direct access to the weights\n",
    "    a_sh = me._objects[state_id].get()\n",
    "    # TODO: this should be stored automatically\n",
    "    me._objects[a_sh.id] = a_sh\n",
    "    new_state_ids.append(a_sh.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_plan.replace_ids(fetched_plan.state_ids, new_state_ids)\n",
    "fetched_plan.state_ids = new_state_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2805], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = th.tensor([1.])\n",
    "print(fetched_plan(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
